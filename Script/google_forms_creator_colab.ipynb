{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggMxT1rkaaW9"
      },
      "source": [
        "# ğŸ“ Google Forms Creator for SME Evaluation\n",
        "\n",
        "This notebook creates Google Forms with:\n",
        "- âœ… Automatic Google Drive spreadsheet integration\n",
        "- âœ… Progress saving for responders\n",
        "- âœ… Proper page breaks between samples\n",
        "- âœ… Professional formatting\n",
        "\n",
        "## ğŸš€ Quick Start:\n",
        "1. Upload your JSON data file to Colab\n",
        "2. Update the `PROJECT_ID` and `JSON_FILE_PATH` below\n",
        "3. Run all cells\n",
        "4. Get your form URLs and spreadsheet link!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfq1CXxxaaW_"
      },
      "source": [
        "## ğŸ“¦ Setup and Authentication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kjKNYsUdaaW_"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -qqq google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bsS6pb1uaaXA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Any, Optional\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from google.auth import default\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_dfYyXYaaXA",
        "outputId": "f6a661c4-2d95-44c9-c032-ea97e7f2c726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”§ Project ID: black-heuristic-463515-f6\n",
            "ğŸ“‚ Data file: /content/evaluation_samples_batch_1.json\n",
            "ğŸ“ Form title: BEACON LLM Evaluation for the Severity Assessment\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”§ CONFIGURATION - UPDATE THESE VALUES\n",
        "PROJECT_ID = \"black-heuristic-463515-f6\"  # Your Google Cloud Project ID\n",
        "BATCH_ID = 1\n",
        "JSON_FILE_PATH = f\"/content/evaluation_samples_batch_{BATCH_ID}.json\"\n",
        "\n",
        "FORM_TITLE = f\"BEACON LLM Evaluation for the Severity Assessment\"\n",
        "\n",
        "print(f\"ğŸ”§ Project ID: {PROJECT_ID}\")\n",
        "print(f\"ğŸ“‚ Data file: {JSON_FILE_PATH}\")\n",
        "print(f\"ğŸ“ Form title: {FORM_TITLE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "komigF1UaaXA",
        "outputId": "3a7f5529-a82d-45d8-d8f6-c5fb7c93f755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google Forms API connected successfully!\n",
            "âœ… Google Drive API connected successfully!\n",
            "âœ… Google Sheets API connected successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set environment variables\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
        "os.environ['GCLOUD_PROJECT'] = PROJECT_ID\n",
        "\n",
        "# Authenticate with broader scope for Drive access\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=[\n",
        "    'https://www.googleapis.com/auth/forms.body',\n",
        "    'https://www.googleapis.com/auth/forms.responses.readonly',\n",
        "    'https://www.googleapis.com/auth/drive',\n",
        "    'https://www.googleapis.com/auth/spreadsheets'\n",
        "])\n",
        "\n",
        "if hasattr(creds, 'with_quota_project'):\n",
        "    creds = creds.with_quota_project(PROJECT_ID)\n",
        "\n",
        "# Build services\n",
        "forms_service = build('forms', 'v1', credentials=creds)\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "sheets_service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "print(\"âœ… Google Forms API connected successfully!\")\n",
        "print(\"âœ… Google Drive API connected successfully!\")\n",
        "print(\"âœ… Google Sheets API connected successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlty6Z8naaXA"
      },
      "source": [
        "## ğŸ“Š Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAkYp4NtaaXA",
        "outputId": "d7508abe-fc4b-48fb-9850-641ea240bf20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Loading data from: /content/evaluation_samples_batch_1.json\n",
            "âœ… Loaded 30 samples!\n",
            "\n",
            "ğŸ“‹ Sample data structure:\n",
            "  â€¢ sample_id: 23\n",
            "  â€¢ domain: Geographic\n",
            "  â€¢ factors_description: Evaluates factors affecting disease transmission potential across geographic areas. Key factors: pop...\n",
            "  â€¢ article_content: Northwestern students and staff have shown concern and support for Chinese citizens in light of the ...\n",
            "  â€¢ reference_score: 5\n",
            "  â€¢ reference_reasoning: All three factors scored at the highest level, indicating a severe outbreak with high potential for ...\n",
            "  â€¢ model_a_score: 5\n",
            "  â€¢ model_a_reasoning: The combination of high population density, high regional connectivity and mobility, and concurrent ...\n",
            "  â€¢ model_b_score: 5\n",
            "  â€¢ model_b_reasoning: All three factors score high, indicating a severe situation. The outbreak originated in a highly pop...\n",
            "  â€¢ model_a_actual: meta-llama\n",
            "  â€¢ model_b_actual: Paschalidis-NOC-Lab\n",
            "  â€¢ article_id: 23\n",
            "\n",
            "ğŸ¯ Ready to create form with 30 samples\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“‚ Load your JSON data\n",
        "print(f\"ğŸ“‚ Loading data from: {JSON_FILE_PATH}\")\n",
        "\n",
        "try:\n",
        "    with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:\n",
        "        sample_data = json.load(f)\n",
        "    print(f\"âœ… Loaded {len(sample_data)} samples!\")\n",
        "\n",
        "    # Show first sample structure\n",
        "    if sample_data:\n",
        "        print(\"\\nğŸ“‹ Sample data structure:\")\n",
        "        first_sample = sample_data[0]\n",
        "        for key in first_sample.keys():\n",
        "            value = str(first_sample[key])[:100] + \"...\" if len(str(first_sample[key])) > 100 else first_sample[key]\n",
        "            print(f\"  â€¢ {key}: {value}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ File not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "print(f\"\\nğŸ¯ Ready to create form with {len(sample_data)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt-nNCPWaaXA"
      },
      "source": [
        "## ğŸš€ Create the Google Form\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VTLl7aM2aaXB"
      },
      "outputs": [],
      "source": [
        "# Add instructions\n",
        "\n",
        "# Improved format optimized for Google Forms plain text display\n",
        "instructions = \"\"\"\n",
        "OVERVIEW\n",
        "You are participating in evaluating AI-generated outbreak severity assessments for news articles about health threats.\n",
        "\n",
        "\n",
        "\n",
        "WHAT YOU'LL REVIEW\n",
        "\n",
        "Article: News article from HealthMap's archived reports of historical disease outbreaks\n",
        "\n",
        "Reference Assessment: Current \"gold standard\" baseline created by GPT-o1 (advanced AI model)\n",
        "â€¢ Includes severity score and detailed reasoning\n",
        "â€¢ Used as our training reference point\n",
        "\n",
        "Model A & Model B Assessments: Two randomized AI model outputs for comparison\n",
        "â€¢ One fine-tuned model (BEACON LLM)\n",
        "â€¢ One base model (Llama-3.1-8B)\n",
        "â€¢ Order is randomized to prevent bias\n",
        "\n",
        "\n",
        "KEY DEFINITIONS\n",
        "\n",
        "Severity Score Scale (1-5):\n",
        "1 = Very Low Risk\n",
        "2 = Low Risk\n",
        "3 = Moderate Risk\n",
        "4 = High Risk\n",
        "5 = Very High Risk\n",
        "\n",
        "Severity Reasoning:\n",
        "Detailed justification explaining the assigned score based on relevant epidemiological, clinical, and contextual factors for the specific risk domain.\n",
        "\n",
        "\n",
        "YOUR EVALUATION TASKS\n",
        "\n",
        "Task 1: Reference Validation\n",
        "Purpose: Validate our \"gold standard\" baseline assessment\n",
        "Your Role: Evaluate whether GPT-o1's risk assessment and reasoning are accurate and appropriate\n",
        "Importance: Ensures our training data quality\n",
        "\n",
        "Task 2: Model Comparison\n",
        "Purpose: Compare two different AI approaches\n",
        "Your Role: Determine which model provides better risk assessment and reasoning\n",
        "Focus: Overall quality, not just agreement with reference\n",
        "\n",
        "Task 3: Expert Assessment (Optional)\n",
        "Purpose: Provide independent expert judgment\n",
        "When to Use: When you believe all AI models significantly over- or under-estimate\n",
        "Your Role: Provide your own expert severity score with justification\n",
        "\n",
        "\n",
        "EVALUATION CRITERIA\n",
        "\n",
        "Please evaluate based on:\n",
        "â€¢ Scientific Accuracy: Correctness of epidemiological and medical information\n",
        "â€¢ Risk Appropriateness: How well the severity score matches the described threat level\n",
        "â€¢ Reasoning Quality: Completeness and quality of the justification\n",
        "\n",
        "\n",
        "SUPPORT\n",
        "For technical issues or questions about this evaluation, please contact: jmyang@bu.edu\n",
        "\n",
        "Thank you for contributing your expertise to improve BEACON LLMs.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H8L90PCaaXB",
        "outputId": "5b006b37-d291-47b7-8b4c-4ff8ebc19fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Form created with ID: 1X2yZlQF-s6Mxkh4NVRVEdGDFn7LKXDUJmP_HA74xuUM\n",
            "âœ… Form description and settings updated successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create basic form (title only)\n",
        "form_request = {\n",
        "    \"info\": {\n",
        "        \"title\": f\"{FORM_TITLE} - Batch {BATCH_ID}\"\n",
        "    }\n",
        "}\n",
        "\n",
        "form = forms_service.forms().create(body=form_request).execute()\n",
        "form_id = form['formId']\n",
        "\n",
        "print(f\"âœ… Form created with ID: {form_id}\")\n",
        "\n",
        "# Step 2: Add description and settings using batchUpdate\n",
        "try:\n",
        "    forms_service.forms().batchUpdate(\n",
        "        formId=form_id,\n",
        "        body={\n",
        "            \"requests\": [\n",
        "                {\n",
        "                    \"updateFormInfo\": {\n",
        "                        \"info\": {\n",
        "                            \"title\": f\"{FORM_TITLE} - Batch {BATCH_ID}\",\n",
        "                            \"description\": instructions\n",
        "                        },\n",
        "                        \"updateMask\": \"description\"\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"updateSettings\": {\n",
        "                        \"settings\": {\n",
        "                            \"quizSettings\": {\n",
        "                                \"isQuiz\": False\n",
        "                            }\n",
        "                        },\n",
        "                        \"updateMask\": \"quizSettings\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "    print(\"âœ… Form description and settings updated successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Error updating form info: {e}\")\n",
        "    print(\"   Form created but description may need manual addition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTiCPG4kaaXB",
        "outputId": "f4f88d49-b7af-48be-b943-17be2400240f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Creating Google Spreadsheet for responses...\n",
            "âœ… Spreadsheet created: https://docs.google.com/spreadsheets/d/1gqLMMr6A2WfhS26ar19DpBAvDPo2VSCvj9uzEaqZvVs\n",
            "âœ… Form settings updated\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Create and link Google Spreadsheet for responses\n",
        "print(\"ğŸ“Š Creating Google Spreadsheet for responses...\")\n",
        "\n",
        "# Create spreadsheet\n",
        "spreadsheet_body = {\n",
        "    'properties': {\n",
        "        'title': f'SME Evaluation Responses - Batch {BATCH_ID}'\n",
        "    }\n",
        "}\n",
        "\n",
        "spreadsheet = sheets_service.spreadsheets().create(body=spreadsheet_body).execute()\n",
        "spreadsheet_id = spreadsheet['spreadsheetId']\n",
        "spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}\"\n",
        "\n",
        "print(f\"âœ… Spreadsheet created: {spreadsheet_url}\")\n",
        "\n",
        "# Link form to spreadsheet\n",
        "try:\n",
        "    # Update form settings\n",
        "    forms_service.forms().batchUpdate(\n",
        "        formId=form_id,\n",
        "        body={\n",
        "            \"requests\": [{\n",
        "                \"updateSettings\": {\n",
        "                    \"settings\": {\n",
        "                        \"quizSettings\": {\n",
        "                            \"isQuiz\": False\n",
        "                        }\n",
        "                    },\n",
        "                    \"updateMask\": \"quizSettings\"\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "    print(\"âœ… Form settings updated\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Note: Manual spreadsheet linking may be required. Error: {e}\")\n",
        "    print(\"You can manually link the spreadsheet in the Google Forms interface.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIgAqOZOaaXB",
        "outputId": "37c818cb-97b6-4c03-c8aa-fee5110e01a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Adding form content with page breaks and tracking fields...\n",
            "ğŸ“ Prepared 363 form items with enhanced page breaks and tracking fields\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Add form content with proper page breaks and tracking fields\n",
        "print(\"ğŸ“ Adding form content with page breaks and tracking fields...\")\n",
        "\n",
        "all_requests = []\n",
        "current_index = 0\n",
        "\n",
        "# Add SME Email field (Page 1)\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"title\": \"ğŸ‘¤ Your Email Address (Required)\",\n",
        "            \"description\": \"Please enter your email address. This helps us track your progress and allows you to save and return to complete the form later.\",\n",
        "            \"questionItem\": {\n",
        "                \"question\": {\n",
        "                    \"required\": True,\n",
        "                    \"textQuestion\": {\"paragraph\": False}\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "# Add page break after email\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"pageBreakItem\": {}\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "# Add introduction text after page break\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"title\": \"ğŸ“‹ Begin Sample Evaluation\",\n",
        "            \"description\": \"You will now evaluate each sample on a separate page. Your progress is automatically saved. You can return to this form later using the same email address.\",\n",
        "            \"textItem\": {}\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "# Add questions for each sample with tracking fields\n",
        "for i, sample in enumerate(sample_data):\n",
        "    sample_num = i + 1\n",
        "    sample_id = sample.get('sample_id', 'Unknown')\n",
        "\n",
        "    # Add page break before each sample (except the first)\n",
        "    if i > 0:\n",
        "        all_requests.append({\n",
        "            \"createItem\": {\n",
        "                \"item\": {\n",
        "                    \"pageBreakItem\": {}\n",
        "                },\n",
        "                \"location\": {\"index\": current_index}\n",
        "            }\n",
        "        })\n",
        "        current_index += 1\n",
        "\n",
        "        # Add progress indicator after page break\n",
        "        all_requests.append({\n",
        "            \"createItem\": {\n",
        "                \"item\": {\n",
        "                    \"title\": f\"ğŸ“„ Sample {sample_id}\",\n",
        "                    \"description\": f\"Progress: {((i)/len(sample_data)*100):.0f}% Complete\\n\\n\",\n",
        "                    \"textItem\": {}\n",
        "                },\n",
        "                \"location\": {\"index\": current_index}\n",
        "            }\n",
        "        })\n",
        "        current_index += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Add the sample header with corrected field reference\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"ğŸ“Š Sample {sample_id} - Overview\",\n",
        "                \"description\": f\"ğŸ¯ Domain: {sample.get('domain', 'Unknown Domain')}\\n\\nğŸ” Risk Factors: {sample.get('factors_description', 'Unknown Factors')}\\n\\nğŸ“ˆ Progress: {sample_num}/{len(sample_data)} samples\",\n",
        "                \"textItem\": {}\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Add article content with better formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"ğŸ“° Article Content - Sample {sample_id}\",\n",
        "                \"description\": f\"Please read the following article carefully:\\n\\n---\\n\\n{sample.get('article_content', 'Article content')}\\n\\n---\",\n",
        "                \"textItem\": {}\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Add Reference assessment with enhanced formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"ğŸ¯ Task 1: Reference Assessment (GPT-o1) - Sample {sample_id}\",\n",
        "                \"description\": f\"\"\"ğŸ“Š Severity Score: {sample.get('reference_score', 'X')}/5\n",
        "\n",
        "ğŸ’­ Severity Reasoning:\n",
        "{sample.get('reference_reasoning', 'Reference reasoning')}\n",
        "\n",
        "---\n",
        "Please evaluate this reference assessment below.\"\"\",\n",
        "                \"textItem\": {}\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Reference risk score question with enhanced options\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q1. ğŸ“Š Reference Risk Score Assessment - Sample {sample_id} (Required)\",\n",
        "                \"description\": f\"Is the reference severity score ({sample.get('reference_score', 'X')}/5) appropriate for this scenario?\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": True,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"ğŸ“‰ Too low (should be higher)\"},\n",
        "                                {\"value\": \"âœ… Appropriate (correct level)\"},\n",
        "                                {\"value\": \"ğŸ“ˆ Too high (should be lower)\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Reference reasoning question\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q2. ğŸ’­ Reference Reasoning Quality - Sample {sample_id} (Required)\",\n",
        "                \"description\": f\"Rate the accuracy and quality of the reference reasoning:\\n\\n{sample.get('reference_reasoning', 'Reference reasoning')}\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": True,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"âŒ Poor (Major errors or gaps)\"},\n",
        "                                {\"value\": \"âš ï¸ Average (Acceptable but could improve)\"},\n",
        "                                {\"value\": \"âœ… Good (Accurate and well-reasoned)\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Model comparison display with enhanced formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"ğŸ†š Task 2: Model Comparison - Sample {sample_id}\",\n",
        "                \"description\": f\"\"\"Compare these two AI model assessments:\n",
        "\n",
        "ğŸ¤– Model A Assessment:\n",
        "ğŸ“Š Severity Score: {sample.get('model_a_score', 'Y')}/5\n",
        "ğŸ’­ Reasoning: {sample.get('model_a_reasoning', 'Model A reasoning')}\n",
        "\n",
        "---\n",
        "\n",
        "ğŸ¤– Model B Assessment:\n",
        "ğŸ“Š Severity Score: {sample.get('model_b_score', 'Z')}/5\n",
        "ğŸ’­ Reasoning: {sample.get('model_b_reasoning', 'Model B reasoning')}\n",
        "\n",
        "---\n",
        "Please compare these models below.\"\"\",\n",
        "                \"textItem\": {}\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Model comparison questions with enhanced options\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q3. ğŸ“Š Model Score Comparison - Sample {sample_id} (Required)\",\n",
        "                \"description\": f\"Which model's severity score is more accurate?\\n\\nğŸ¤– Model A: {sample.get('model_a_score', 'Y')}/5\\nğŸ¤– Model B: {sample.get('model_b_score', 'Z')}/5\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": True,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"ğŸ¥‡ Model A is clearly better\"},\n",
        "                                {\"value\": \"ğŸ¥ˆ Model A is slightly better\"},\n",
        "                                {\"value\": \"ğŸ¤ Both are equivalent\"},\n",
        "                                {\"value\": \"ğŸ¥ˆ Model B is slightly better\"},\n",
        "                                {\"value\": \"ğŸ¥‡ Model B is clearly better\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Model reasoning comparison\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q4. ğŸ’­ Model Reasoning Comparison - Sample {sample_id} (Required)\",\n",
        "                \"description\": f\"Which model provides better reasoning and justification?\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": True,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"ğŸ¥‡ Model A reasoning is much better\"},\n",
        "                                {\"value\": \"ğŸ¥ˆ Model A reasoning is slightly better\"},\n",
        "                                {\"value\": \"ğŸ¤ Both reasoning are equivalent\"},\n",
        "                                {\"value\": \"ğŸ¥ˆ Model B reasoning is slightly better\"},\n",
        "                                {\"value\": \"ğŸ¥‡ Model B reasoning is much better\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Expert score (optional) with enhanced formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q5. ğŸ‘¨â€âš•ï¸ Your Expert Assessment - Sample {sample_id} (Optional)\",\n",
        "                \"description\": \"What risk score would you assign based on your expertise? (Only provide if you believe all AI assessments are significantly off)\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": False,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"1ï¸âƒ£ Very low risk\"},\n",
        "                                {\"value\": \"2ï¸âƒ£ Low risk\"},\n",
        "                                {\"value\": \"3ï¸âƒ£ Moderate risk\"},\n",
        "                                {\"value\": \"4ï¸âƒ£ High risk\"},\n",
        "                                {\"value\": \"5ï¸âƒ£ Very high risk\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Comments with enhanced description\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q6. ğŸ’¬ Additional Comments - Sample {sample_id} (Optional)\",\n",
        "                \"description\": \"Any critical factors missed by all assessments or additional comments about this sample?\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": False,\n",
        "                        \"textQuestion\": {\"paragraph\": True}\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "# Add final page break with completion message\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"pageBreakItem\": {}\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "# Add completion message\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"title\": \"ğŸ‰ Evaluation Complete!\",\n",
        "            \"description\": \"Thank you for completing the evaluation. Your responses have been automatically saved to our spreadsheet. You may now submit the form.\",\n",
        "            \"textItem\": {}\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "print(f\"ğŸ“ Prepared {len(all_requests)} form items with enhanced page breaks and tracking fields\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54vAIO0naaXC",
        "outputId": "e5206096-8765-489f-eef3-6afdece7b5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Adding form items...\n",
            "âœ… Batch 1/73 - Added 5 items (Progress: 1.4%)\n",
            "âœ… Batch 2/73 - Added 5 items (Progress: 2.8%)\n",
            "âœ… Batch 3/73 - Added 5 items (Progress: 4.1%)\n",
            "âœ… Batch 4/73 - Added 5 items (Progress: 5.5%)\n",
            "âœ… Batch 5/73 - Added 5 items (Progress: 6.9%)\n",
            "âœ… Batch 6/73 - Added 5 items (Progress: 8.3%)\n",
            "âœ… Batch 7/73 - Added 5 items (Progress: 9.6%)\n",
            "âœ… Batch 8/73 - Added 5 items (Progress: 11.0%)\n",
            "âœ… Batch 9/73 - Added 5 items (Progress: 12.4%)\n",
            "âœ… Batch 10/73 - Added 5 items (Progress: 13.8%)\n",
            "âœ… Batch 11/73 - Added 5 items (Progress: 15.2%)\n",
            "âœ… Batch 12/73 - Added 5 items (Progress: 16.5%)\n",
            "âœ… Batch 13/73 - Added 5 items (Progress: 17.9%)\n",
            "âœ… Batch 14/73 - Added 5 items (Progress: 19.3%)\n",
            "âœ… Batch 15/73 - Added 5 items (Progress: 20.7%)\n",
            "âœ… Batch 16/73 - Added 5 items (Progress: 22.0%)\n",
            "âœ… Batch 17/73 - Added 5 items (Progress: 23.4%)\n",
            "âœ… Batch 18/73 - Added 5 items (Progress: 24.8%)\n",
            "âœ… Batch 19/73 - Added 5 items (Progress: 26.2%)\n",
            "âœ… Batch 20/73 - Added 5 items (Progress: 27.5%)\n",
            "âœ… Batch 21/73 - Added 5 items (Progress: 28.9%)\n",
            "âœ… Batch 22/73 - Added 5 items (Progress: 30.3%)\n",
            "âœ… Batch 23/73 - Added 5 items (Progress: 31.7%)\n",
            "âœ… Batch 24/73 - Added 5 items (Progress: 33.1%)\n",
            "âœ… Batch 25/73 - Added 5 items (Progress: 34.4%)\n",
            "âœ… Batch 26/73 - Added 5 items (Progress: 35.8%)\n",
            "âœ… Batch 27/73 - Added 5 items (Progress: 37.2%)\n",
            "âœ… Batch 28/73 - Added 5 items (Progress: 38.6%)\n",
            "âœ… Batch 29/73 - Added 5 items (Progress: 39.9%)\n",
            "âœ… Batch 30/73 - Added 5 items (Progress: 41.3%)\n",
            "âœ… Batch 31/73 - Added 5 items (Progress: 42.7%)\n",
            "âœ… Batch 32/73 - Added 5 items (Progress: 44.1%)\n",
            "âœ… Batch 33/73 - Added 5 items (Progress: 45.5%)\n",
            "âœ… Batch 34/73 - Added 5 items (Progress: 46.8%)\n",
            "âœ… Batch 35/73 - Added 5 items (Progress: 48.2%)\n",
            "âœ… Batch 36/73 - Added 5 items (Progress: 49.6%)\n",
            "âœ… Batch 37/73 - Added 5 items (Progress: 51.0%)\n",
            "âœ… Batch 38/73 - Added 5 items (Progress: 52.3%)\n",
            "âœ… Batch 39/73 - Added 5 items (Progress: 53.7%)\n",
            "âœ… Batch 40/73 - Added 5 items (Progress: 55.1%)\n",
            "âœ… Batch 41/73 - Added 5 items (Progress: 56.5%)\n",
            "âœ… Batch 42/73 - Added 5 items (Progress: 57.9%)\n",
            "âœ… Batch 43/73 - Added 5 items (Progress: 59.2%)\n",
            "âœ… Batch 44/73 - Added 5 items (Progress: 60.6%)\n",
            "âœ… Batch 45/73 - Added 5 items (Progress: 62.0%)\n",
            "âœ… Batch 46/73 - Added 5 items (Progress: 63.4%)\n",
            "âœ… Batch 47/73 - Added 5 items (Progress: 64.7%)\n",
            "âœ… Batch 48/73 - Added 5 items (Progress: 66.1%)\n",
            "âœ… Batch 49/73 - Added 5 items (Progress: 67.5%)\n",
            "âœ… Batch 50/73 - Added 5 items (Progress: 68.9%)\n",
            "âœ… Batch 51/73 - Added 5 items (Progress: 70.2%)\n",
            "âœ… Batch 52/73 - Added 5 items (Progress: 71.6%)\n",
            "âœ… Batch 53/73 - Added 5 items (Progress: 73.0%)\n",
            "âœ… Batch 54/73 - Added 5 items (Progress: 74.4%)\n",
            "âœ… Batch 55/73 - Added 5 items (Progress: 75.8%)\n",
            "âœ… Batch 56/73 - Added 5 items (Progress: 77.1%)\n",
            "âœ… Batch 57/73 - Added 5 items (Progress: 78.5%)\n",
            "âœ… Batch 58/73 - Added 5 items (Progress: 79.9%)\n",
            "âœ… Batch 59/73 - Added 5 items (Progress: 81.3%)\n",
            "âœ… Batch 60/73 - Added 5 items (Progress: 82.6%)\n",
            "âœ… Batch 61/73 - Added 5 items (Progress: 84.0%)\n",
            "âœ… Batch 62/73 - Added 5 items (Progress: 85.4%)\n",
            "âœ… Batch 63/73 - Added 5 items (Progress: 86.8%)\n",
            "âœ… Batch 64/73 - Added 5 items (Progress: 88.2%)\n",
            "âœ… Batch 65/73 - Added 5 items (Progress: 89.5%)\n",
            "âœ… Batch 66/73 - Added 5 items (Progress: 90.9%)\n",
            "âœ… Batch 67/73 - Added 5 items (Progress: 92.3%)\n",
            "âœ… Batch 68/73 - Added 5 items (Progress: 93.7%)\n",
            "âœ… Batch 69/73 - Added 5 items (Progress: 95.0%)\n",
            "âœ… Batch 70/73 - Added 5 items (Progress: 96.4%)\n",
            "âœ… Batch 71/73 - Added 5 items (Progress: 97.8%)\n",
            "âœ… Batch 72/73 - Added 5 items (Progress: 99.2%)\n",
            "âœ… Batch 73/73 - Added 3 items (Progress: 100.0%)\n",
            "\n",
            "ğŸ‰ Successfully added 363/363 items to the form!\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Add all form items in batches with better error handling\n",
        "print(\"ğŸš€ Adding form items...\")\n",
        "\n",
        "batch_size = 5  # Smaller batches for better reliability\n",
        "success_count = 0\n",
        "total_items = len(all_requests)\n",
        "failed_items = []\n",
        "\n",
        "for i in range(0, total_items, batch_size):\n",
        "    batch = all_requests[i:i+batch_size]\n",
        "    batch_num = (i // batch_size) + 1\n",
        "    total_batches = (total_items + batch_size - 1) // batch_size\n",
        "\n",
        "    try:\n",
        "        forms_service.forms().batchUpdate(\n",
        "            formId=form_id,\n",
        "            body={\"requests\": batch}\n",
        "        ).execute()\n",
        "        success_count += len(batch)\n",
        "        progress = (success_count / total_items) * 100\n",
        "        print(f\"âœ… Batch {batch_num}/{total_batches} - Added {len(batch)} items (Progress: {progress:.1f}%)\")\n",
        "\n",
        "        # Small delay to avoid rate limits\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Batch {batch_num} error: {str(e)[:100]}...\")\n",
        "        # Try individually with better error handling\n",
        "        for j, request in enumerate(batch):\n",
        "            item_num = i + j + 1\n",
        "            try:\n",
        "                forms_service.forms().batchUpdate(\n",
        "                    formId=form_id,\n",
        "                    body={\"requests\": [request]}\n",
        "                ).execute()\n",
        "                success_count += 1\n",
        "                print(f\"âœ… Individual item {item_num}/{total_items} added\")\n",
        "                time.sleep(0.2)\n",
        "            except Exception as eq:\n",
        "                failed_items.append({\n",
        "                    'item_number': item_num,\n",
        "                    'request': request,\n",
        "                    'error': str(eq)[:100]\n",
        "                })\n",
        "                print(f\"âŒ Individual error {item_num}: {str(eq)[:50]}...\")\n",
        "\n",
        "print(f\"\\nğŸ‰ Successfully added {success_count}/{total_items} items to the form!\")\n",
        "\n",
        "if failed_items:\n",
        "    print(f\"âš ï¸  {len(failed_items)} items failed to add:\")\n",
        "    for item in failed_items[:5]:  # Show first 5 failures\n",
        "        print(f\"   Item {item['item_number']}: {item['error']}\")\n",
        "    if len(failed_items) > 5:\n",
        "        print(f\"   ... and {len(failed_items) - 5} more\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENsSAD_ZaaXC"
      },
      "source": [
        "## ğŸ“‹ Form Information and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRIFXKptaaXC",
        "outputId": "578ea6ff-8dfe-48ac-9e30-06a79a870670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Generating form information and links...\n",
            "âœ… Form URLs generated successfully\n",
            "ğŸ’¾ Form information saved to: /content/form_result_batch_1.json\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Get form URLs and create comprehensive results\n",
        "print(\"ğŸ“Š Generating form information and links...\")\n",
        "\n",
        "try:\n",
        "    # Get the form data to extract the correct URLs\n",
        "    form_data = forms_service.forms().get(formId=form_id).execute()\n",
        "\n",
        "    # Extract the correct URLs\n",
        "    edit_url = f\"https://docs.google.com/forms/d/{form_id}/edit\"\n",
        "\n",
        "    # The responderUri gives us the correct public URL\n",
        "    if 'responderUri' in form_data:\n",
        "        view_url = form_data['responderUri']\n",
        "    else:\n",
        "        # Fallback URL format\n",
        "        view_url = f\"https://docs.google.com/forms/d/{form_id}/viewform\"\n",
        "\n",
        "    # Responses URL - this goes to the responses tab of the edit page\n",
        "    responses_url = f\"https://docs.google.com/forms/d/{form_id}/edit#responses\"\n",
        "\n",
        "    print(\"âœ… Form URLs generated successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Using fallback URLs due to error: {e}\")\n",
        "    # Use fallback URLs\n",
        "    edit_url = f\"https://docs.google.com/forms/d/{form_id}/edit\"\n",
        "    view_url = f\"https://docs.google.com/forms/d/{form_id}/viewform\"\n",
        "    responses_url = f\"https://docs.google.com/forms/d/{form_id}/edit#responses\"\n",
        "\n",
        "# Comprehensive form information\n",
        "form_info = {\n",
        "    'form_id': form_id,\n",
        "    'edit_url': edit_url,\n",
        "    'view_url': view_url,\n",
        "    'responses_url': responses_url,\n",
        "    'spreadsheet_id': spreadsheet_id,\n",
        "    'spreadsheet_url': spreadsheet_url,\n",
        "    'total_samples': len(sample_data),\n",
        "    'json_file_used': JSON_FILE_PATH,\n",
        "    'project_id': PROJECT_ID,\n",
        "    'form_title': FORM_TITLE,\n",
        "    'batch_id': BATCH_ID,\n",
        "    'features': {\n",
        "        'progress_saving': True,\n",
        "        'page_breaks': True,\n",
        "        'spreadsheet_integration': True,\n",
        "        'enhanced_formatting': True\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to file\n",
        "output_file = f'/content/form_result_batch_{BATCH_ID}.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(form_info, f, indent=2)\n",
        "\n",
        "print(f\"ğŸ’¾ Form information saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qGDUOgfaaXC",
        "outputId": "45760f99-b57c-418b-b593-fe2ee23a2dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ‰ FORM CREATION COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "\n",
            "ğŸ“ **Form Title:** BEACON LLM Evaluation for the Severity Assessment - Batch 1\n",
            "ğŸ†” **Form ID:** 1X2yZlQF-s6Mxkh4NVRVEdGDFn7LKXDUJmP_HA74xuUM\n",
            "ğŸ“Š **Total Samples:** 30\n",
            "\n",
            "ğŸ”— **Important Links:**\n",
            "   ğŸ“ Edit Form: https://docs.google.com/forms/d/1X2yZlQF-s6Mxkh4NVRVEdGDFn7LKXDUJmP_HA74xuUM/edit\n",
            "   ğŸ‘€ Public Form (Share with SMEs): https://docs.google.com/forms/d/e/1FAIpQLSf3T4EaSVrtLHrniT_64qa6PUFtyL8d8AZrvNhFHXzZrERLRA/viewform\n",
            "   ğŸ“ˆ View Responses: https://docs.google.com/forms/d/1X2yZlQF-s6Mxkh4NVRVEdGDFn7LKXDUJmP_HA74xuUM/edit#responses\n",
            "   ğŸ“Š Response Spreadsheet: https://docs.google.com/spreadsheets/d/1gqLMMr6A2WfhS26ar19DpBAvDPo2VSCvj9uzEaqZvVs\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Display comprehensive results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ FORM CREATION COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nğŸ“ **Form Title:** {FORM_TITLE} - Batch {BATCH_ID}\")\n",
        "print(f\"ğŸ†” **Form ID:** {form_id}\")\n",
        "print(f\"ğŸ“Š **Total Samples:** {len(sample_data)}\")\n",
        "\n",
        "print(\"\\nğŸ”— **Important Links:**\")\n",
        "print(f\"   ğŸ“ Edit Form: {edit_url}\")\n",
        "print(f\"   ğŸ‘€ Public Form (Share with SMEs): {view_url}\")\n",
        "print(f\"   ğŸ“ˆ View Responses: {responses_url}\")\n",
        "print(f\"   ğŸ“Š Response Spreadsheet: {spreadsheet_url}\")\n",
        "\n",
        "\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}