{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggMxT1rkaaW9"
      },
      "source": [
        "# ğŸ“ Google Forms Creator for SME Evaluation\n",
        "\n",
        "This notebook creates Google Forms with:\n",
        "- âœ… Automatic Google Drive spreadsheet integration\n",
        "- âœ… Progress saving for responders\n",
        "- âœ… Proper page breaks between samples\n",
        "- âœ… Professional formatting\n",
        "\n",
        "## ğŸš€ Quick Start:\n",
        "1. Upload your JSON data file to Colab\n",
        "2. Update the `PROJECT_ID` and `JSON_FILE_PATH` below\n",
        "3. Run all cells\n",
        "4. Get your form URLs and spreadsheet link!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfq1CXxxaaW_"
      },
      "source": [
        "## ğŸ“¦ Setup and Authentication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kjKNYsUdaaW_"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -qqq google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bsS6pb1uaaXA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Any, Optional\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from google.auth import default\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_dfYyXYaaXA",
        "outputId": "01a8ebf6-5bca-40b0-8137-e4815d6d6489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Project ID: black-heuristic-463515-f6\n",
            "ğŸ“‚ Data file: /content/sample_data_template_1.json\n",
            "ğŸ“ Form title: BEACON LLM Model Evaluation for the Severity Assessment\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”§ CONFIGURATION - UPDATE THESE VALUES\n",
        "PROJECT_ID = \"black-heuristic-xxxx-f6\"  # Your Google Cloud Project ID\n",
        "BATCH_ID = 1\n",
        "JSON_FILE_PATH = f\"/content/sample_data_template_{BATCH_ID}.json\"\n",
        "\n",
        "FORM_TITLE = f\"BEACON LLM Evaluation for the Severity Assessment\"\n",
        "\n",
        "print(f\"ğŸ”§ Project ID: {PROJECT_ID}\")\n",
        "print(f\"ğŸ“‚ Data file: {JSON_FILE_PATH}\")\n",
        "print(f\"ğŸ“ Form title: {FORM_TITLE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "komigF1UaaXA",
        "outputId": "68eb74e9-e3aa-40c3-8447-4fec6db05c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Google Forms API connected successfully!\n",
            "âœ… Google Drive API connected successfully!\n",
            "âœ… Google Sheets API connected successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set environment variables\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
        "os.environ['GCLOUD_PROJECT'] = PROJECT_ID\n",
        "\n",
        "# Authenticate with broader scope for Drive access\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=[\n",
        "    'https://www.googleapis.com/auth/forms.body',\n",
        "    'https://www.googleapis.com/auth/forms.responses.readonly',\n",
        "    'https://www.googleapis.com/auth/drive',\n",
        "    'https://www.googleapis.com/auth/spreadsheets'\n",
        "])\n",
        "\n",
        "if hasattr(creds, 'with_quota_project'):\n",
        "    creds = creds.with_quota_project(PROJECT_ID)\n",
        "\n",
        "# Build services\n",
        "forms_service = build('forms', 'v1', credentials=creds)\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "sheets_service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "print(\"âœ… Google Forms API connected successfully!\")\n",
        "print(\"âœ… Google Drive API connected successfully!\")\n",
        "print(\"âœ… Google Sheets API connected successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlty6Z8naaXA"
      },
      "source": [
        "## ğŸ“Š Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAkYp4NtaaXA",
        "outputId": "6a02d737-93a4-4901-ecb6-8b09cc863e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ Loading data from: /content/sample_data_template_1.json\n",
            "âœ… Loaded 2 samples!\n",
            "\n",
            "ğŸ“‹ Sample data structure:\n",
            "  â€¢ title: Zika Outbreak in Brazil - Travel Alert\n",
            "  â€¢ domain: Geographic Spread\n",
            "  â€¢ factors_description: This domain evaluates factors including: Geographic proximity, Travel patterns, and Population densi...\n",
            "  â€¢ article_content: Health officials in Brazil have confirmed 150 new cases of Zika virus in the past week, primarily co...\n",
            "  â€¢ reference_score: 4\n",
            "  â€¢ reference_reasoning: High risk due to urban concentration, overwhelmed healthcare system, and high travel season coincidi...\n",
            "  â€¢ model_a_score: 3\n",
            "  â€¢ model_a_reasoning: Moderate risk. While the case count is significant, the outbreak appears geographically contained to...\n",
            "  â€¢ model_b_score: 4\n",
            "  â€¢ model_b_reasoning: High risk assessment based on healthcare system strain, timing during travel season, and potential f...\n",
            "\n",
            "ğŸ¯ Ready to create form with 2 samples\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“‚ Load your JSON data\n",
        "print(f\"ğŸ“‚ Loading data from: {JSON_FILE_PATH}\")\n",
        "\n",
        "try:\n",
        "    with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:\n",
        "        sample_data = json.load(f)\n",
        "    print(f\"âœ… Loaded {len(sample_data)} samples!\")\n",
        "\n",
        "    # Show first sample structure\n",
        "    if sample_data:\n",
        "        print(\"\\nğŸ“‹ Sample data structure:\")\n",
        "        first_sample = sample_data[0]\n",
        "        for key in first_sample.keys():\n",
        "            value = str(first_sample[key])[:100] + \"...\" if len(str(first_sample[key])) > 100 else first_sample[key]\n",
        "            print(f\"  â€¢ {key}: {value}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ File not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "print(f\"\\nğŸ¯ Ready to create form with {len(sample_data)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt-nNCPWaaXA"
      },
      "source": [
        "## ğŸš€ Create the Google Form\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTLl7aM2aaXB"
      },
      "outputs": [],
      "source": [
        "# Add instructions\n",
        "\n",
        "# Improved format optimized for Google Forms plain text display\n",
        "instructions = \"\"\"\n",
        "OVERVIEW\n",
        "You are participating in evaluating AI-generated outbreak severity assessments for news articles about health threats.\n",
        "\n",
        "\n",
        "\n",
        "WHAT YOU'LL REVIEW\n",
        "\n",
        "Article: News article from HealthMap's archived reports of historical disease outbreaks\n",
        "\n",
        "Reference Assessment: Current \"gold standard\" baseline created by GPT-o1 (advanced AI model)\n",
        "â€¢ Includes severity score and detailed reasoning\n",
        "â€¢ Used as our training reference point\n",
        "\n",
        "Model A & Model B Assessments: Two randomized AI model outputs for comparison\n",
        "â€¢ One fine-tuned model (BEACON LLM)\n",
        "â€¢ One base model (Llama-3.1-8B)\n",
        "â€¢ Order is randomized to prevent bias\n",
        "\n",
        "\n",
        "KEY DEFINITIONS\n",
        "\n",
        "Severity Score Scale (1-5):\n",
        "1 = Very Low Risk\n",
        "2 = Low Risk\n",
        "3 = Moderate Risk\n",
        "4 = High Risk\n",
        "5 = Very High Risk\n",
        "\n",
        "Severity Reasoning:\n",
        "Detailed justification explaining the assigned score based on relevant epidemiological, clinical, and contextual factors for the specific risk domain.\n",
        "\n",
        "\n",
        "YOUR EVALUATION TASKS\n",
        "\n",
        "Task 1: Reference Validation\n",
        "Purpose: Validate our \"gold standard\" baseline assessment\n",
        "Your Role: Evaluate whether GPT-o1's risk assessment and reasoning are accurate and appropriate\n",
        "Importance: Ensures our training data quality\n",
        "\n",
        "Task 2: Model Comparison\n",
        "Purpose: Compare two different AI approaches\n",
        "Your Role: Determine which model provides better risk assessment and reasoning\n",
        "Focus: Overall quality, not just agreement with reference\n",
        "\n",
        "Task 3: Expert Assessment (Optional)\n",
        "Purpose: Provide independent expert judgment\n",
        "When to Use: When you believe all AI models significantly over- or under-estimate\n",
        "Your Role: Provide your own expert severity score with justification\n",
        "\n",
        "\n",
        "EVALUATION CRITERIA\n",
        "\n",
        "Please evaluate based on:\n",
        "â€¢ Scientific Accuracy: Correctness of epidemiological and medical information\n",
        "â€¢ Risk Appropriateness: How well the severity score matches the described threat level\n",
        "â€¢ Reasoning Quality: Completeness and quality of the justification\n",
        "\n",
        "\n",
        "SUPPORT\n",
        "For technical issues or questions about this evaluation, please contact: jmyang@bu.edu\n",
        "\n",
        "Thank you for contributing your expertise to improve BEACON LLMs.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H8L90PCaaXB",
        "outputId": "205b4c25-abd0-4b33-9d86-8a68c121b4d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Form created with ID: 1lN03uLEPUREUwAQ5a-QYyxn0MPe6gtXc2Vl2luPAzlE\n",
            "âœ… Form description and settings updated successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create basic form (title only)\n",
        "form_request = {\n",
        "    \"info\": {\n",
        "        \"title\": f\"{FORM_TITLE} - Batch {BATCH_ID}\"\n",
        "    }\n",
        "}\n",
        "\n",
        "form = forms_service.forms().create(body=form_request).execute()\n",
        "form_id = form['formId']\n",
        "\n",
        "print(f\"âœ… Form created with ID: {form_id}\")\n",
        "\n",
        "# Step 2: Add description and settings using batchUpdate\n",
        "try:\n",
        "    forms_service.forms().batchUpdate(\n",
        "        formId=form_id,\n",
        "        body={\n",
        "            \"requests\": [\n",
        "                {\n",
        "                    \"updateFormInfo\": {\n",
        "                        \"info\": {\n",
        "                            \"title\": f\"{FORM_TITLE} - Batch {BATCH_ID}\",\n",
        "                            \"description\": instructions\n",
        "                        },\n",
        "                        \"updateMask\": \"description\"\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"updateSettings\": {\n",
        "                        \"settings\": {\n",
        "                            \"quizSettings\": {\n",
        "                                \"isQuiz\": False\n",
        "                            }\n",
        "                        },\n",
        "                        \"updateMask\": \"quizSettings\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "    print(\"âœ… Form description and settings updated successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Error updating form info: {e}\")\n",
        "    print(\"   Form created but description may need manual addition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTiCPG4kaaXB",
        "outputId": "8c83ab8f-4474-487b-e056-716c10d7ef25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Creating Google Spreadsheet for responses...\n",
            "âœ… Spreadsheet created: https://docs.google.com/spreadsheets/d/1Wc9Vj_53pdDN7dnem-iVzopVPu5XP_4aY0TOubNY7qg\n",
            "âœ… Form settings updated\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Create and link Google Spreadsheet for responses\n",
        "print(\"ğŸ“Š Creating Google Spreadsheet for responses...\")\n",
        "\n",
        "# Create spreadsheet\n",
        "spreadsheet_body = {\n",
        "    'properties': {\n",
        "        'title': f'SME Evaluation Responses - Batch {BATCH_ID}'\n",
        "    }\n",
        "}\n",
        "\n",
        "spreadsheet = sheets_service.spreadsheets().create(body=spreadsheet_body).execute()\n",
        "spreadsheet_id = spreadsheet['spreadsheetId']\n",
        "spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}\"\n",
        "\n",
        "print(f\"âœ… Spreadsheet created: {spreadsheet_url}\")\n",
        "\n",
        "# Link form to spreadsheet\n",
        "try:\n",
        "    # Update form settings\n",
        "    forms_service.forms().batchUpdate(\n",
        "        formId=form_id,\n",
        "        body={\n",
        "            \"requests\": [{\n",
        "                \"updateSettings\": {\n",
        "                    \"settings\": {\n",
        "                        \"quizSettings\": {\n",
        "                            \"isQuiz\": False\n",
        "                        }\n",
        "                    },\n",
        "                    \"updateMask\": \"quizSettings\"\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "    ).execute()\n",
        "\n",
        "    print(\"âœ… Form settings updated\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Note: Manual spreadsheet linking may be required. Error: {e}\")\n",
        "    print(\"You can manually link the spreadsheet in the Google Forms interface.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIgAqOZOaaXB",
        "outputId": "dc133389-2353-4861-c5a4-f31d77d65e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ Adding form content with page breaks...\n",
            "ğŸ“ Prepared 27 form items with enhanced page breaks\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Add form content with proper page breaks\n",
        "print(\"ğŸ“ Adding form content with page breaks...\")\n",
        "\n",
        "all_requests = []\n",
        "current_index = 0\n",
        "\n",
        "# Add SME Email field (Page 1)\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"title\": \"ğŸ‘¤ Your Email Address (Required)\",\n",
        "            \"description\": \"Please enter your email address. This helps us track your progress and allows you to save and return to complete the form later.\",\n",
        "            \"questionItem\": {\n",
        "                \"question\": {\n",
        "                    \"required\": True,\n",
        "                    \"textQuestion\": {\"paragraph\": False}\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "# Add page break after email (simplified - no title/description)\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"pageBreakItem\": {}\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "# Add introduction text after page break\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"title\": \"ğŸ“‹ Begin Sample Evaluation\",\n",
        "            \"description\": \"You will now evaluate each sample on a separate page. Your progress is automatically saved. You can return to this form later using the same email address.\",\n",
        "            \"textItem\": {}\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "# Add questions for each sample with enhanced page breaks\n",
        "for i, sample in enumerate(sample_data):\n",
        "    sample_num = i + 1\n",
        "\n",
        "    # Add page break before each sample (except the first)\n",
        "    if i > 0:\n",
        "        all_requests.append({\n",
        "            \"createItem\": {\n",
        "                \"item\": {\n",
        "                    \"pageBreakItem\": {}\n",
        "                },\n",
        "                \"location\": {\"index\": current_index}\n",
        "            }\n",
        "        })\n",
        "        current_index += 1\n",
        "\n",
        "        # Add progress indicator after page break\n",
        "        all_requests.append({\n",
        "            \"createItem\": {\n",
        "                \"item\": {\n",
        "                    \"title\": f\"ğŸ“„ Sample {sample_num} of {len(sample_data)}\",\n",
        "                    \"description\": f\"Progress: {((i)/len(sample_data)*100):.0f}% Complete\\n\\nYour responses are automatically saved.\",\n",
        "                    \"textItem\": {}\n",
        "                },\n",
        "                \"location\": {\"index\": current_index}\n",
        "            }\n",
        "        })\n",
        "        current_index += 1\n",
        "\n",
        "    # Add the sample header with enhanced formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"ğŸ“Š Sample {sample_num} - Overview\",\n",
        "                \"description\": f\"ğŸ¯ Domain: {sample.get('domain', 'Unknown Domain')}\\n\\nğŸ” Risk Factors: {sample.get('factors', 'Unknown Factors')}\\n\\nğŸ“ˆ Progress: {sample_num}/{len(sample_data)} samples\",\n",
        "                \"textItem\": {}\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Add article content with better formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"ğŸ“° Article Content - Sample {sample_num}\",\n",
        "                \"description\": f\"Please read the following article carefully:\\n\\n---\\n\\n{sample.get('article_content', 'Article content')}\\n\\n---\",\n",
        "                \"textItem\": {}\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Add Reference assessment with enhanced formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"ğŸ¯ Task 1: Reference Assessment (GPT-o1) - Sample {sample_num}\",\n",
        "                \"description\": f\"\"\"ğŸ“Š Severity Score: {sample.get('reference_score', 'X')}/5\n",
        "\n",
        "ğŸ’­ Severity Reasoning:\n",
        "{sample.get('reference_reasoning', 'Reference reasoning')}\n",
        "\n",
        "---\n",
        "Please evaluate this reference assessment below.\"\"\",\n",
        "                \"textItem\": {}\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Reference risk score question with enhanced options\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q1. ğŸ“Š Reference Risk Score Assessment - Sample {sample_num} (Required)\",\n",
        "                \"description\": f\"Is the reference severity score ({sample.get('reference_score', 'X')}/5) appropriate for this scenario?\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": True,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"ğŸ“‰ Too low (should be higher)\"},\n",
        "                                {\"value\": \"âœ… Appropriate (correct level)\"},\n",
        "                                {\"value\": \"ğŸ“ˆ Too high (should be lower)\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Reference reasoning question\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q2. ğŸ’­ Reference Reasoning Quality - Sample {sample_num} (Required)\",\n",
        "                \"description\": f\"Rate the accuracy and quality of the reference reasoning:\\n\\n{sample.get('reference_reasoning', 'Reference reasoning')[:200]}{'...' if len(str(sample.get('reference_reasoning', ''))) > 200 else ''}\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": True,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"âŒ Poor (Major errors or gaps)\"},\n",
        "                                {\"value\": \"âš ï¸ Average (Acceptable but could improve)\"},\n",
        "                                {\"value\": \"âœ… Good (Accurate and well-reasoned)\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Model comparison display with enhanced formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"ğŸ†š Task 2: Model Comparison - Sample {sample_num}\",\n",
        "                \"description\": f\"\"\"Compare these two AI model assessments:\n",
        "\n",
        "ğŸ¤– Model A Assessment:\n",
        "ğŸ“Š Severity Score: {sample.get('model_a_score', 'Y')}/5\n",
        "ğŸ’­ Reasoning: {sample.get('model_a_reasoning', 'Model A reasoning')}\n",
        "\n",
        "---\n",
        "\n",
        "ğŸ¤– Model B Assessment:\n",
        "ğŸ“Š Severity Score: {sample.get('model_b_score', 'Z')}/5\n",
        "ğŸ’­ Reasoning: {sample.get('model_b_reasoning', 'Model B reasoning')}\n",
        "\n",
        "---\n",
        "Please compare these models below.\"\"\",\n",
        "                \"textItem\": {}\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Model comparison questions with enhanced options\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q3. ğŸ“Š Model Score Comparison - Sample {sample_num} (Required)\",\n",
        "                \"description\": f\"Which model's severity score is more accurate?\\n\\nğŸ¤– Model A: {sample.get('model_a_score', 'Y')}/5\\nğŸ¤– Model B: {sample.get('model_b_score', 'Z')}/5\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": True,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"ğŸ¥‡ Model A is clearly better\"},\n",
        "                                {\"value\": \"ğŸ¥ˆ Model A is slightly better\"},\n",
        "                                {\"value\": \"ğŸ¤ Both are equivalent\"},\n",
        "                                {\"value\": \"ğŸ¥ˆ Model B is slightly better\"},\n",
        "                                {\"value\": \"ğŸ¥‡ Model B is clearly better\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Model reasoning comparison\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q4. ğŸ’­ Model Reasoning Comparison - Sample {sample_num} (Required)\",\n",
        "                \"description\": f\"Which model provides better reasoning and justification?\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": True,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"ğŸ¥‡ Model A reasoning is much better\"},\n",
        "                                {\"value\": \"ğŸ¥ˆ Model A reasoning is slightly better\"},\n",
        "                                {\"value\": \"ğŸ¤ Both reasoning are equivalent\"},\n",
        "                                {\"value\": \"ğŸ¥ˆ Model B reasoning is slightly better\"},\n",
        "                                {\"value\": \"ğŸ¥‡ Model B reasoning is much better\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Expert score (optional) with enhanced formatting\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q5. ğŸ‘¨â€âš•ï¸ Your Expert Assessment - Sample {sample_num} (Optional)\",\n",
        "                \"description\": \"What risk score would you assign based on your expertise? (Only provide if you believe all AI assessments are significantly off)\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": False,\n",
        "                        \"choiceQuestion\": {\n",
        "                            \"type\": \"RADIO\",\n",
        "                            \"options\": [\n",
        "                                {\"value\": \"1ï¸âƒ£ Very low risk\"},\n",
        "                                {\"value\": \"2ï¸âƒ£ Low risk\"},\n",
        "                                {\"value\": \"3ï¸âƒ£ Moderate risk\"},\n",
        "                                {\"value\": \"4ï¸âƒ£ High risk\"},\n",
        "                                {\"value\": \"5ï¸âƒ£ Very high risk\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "    # Comments with enhanced description\n",
        "    all_requests.append({\n",
        "        \"createItem\": {\n",
        "            \"item\": {\n",
        "                \"title\": f\"Q6. ğŸ’¬ Additional Comments - Sample {sample_num} (Optional)\",\n",
        "                \"description\": \"Any critical factors missed by all assessments or additional comments about this sample?\",\n",
        "                \"questionItem\": {\n",
        "                    \"question\": {\n",
        "                        \"required\": False,\n",
        "                        \"textQuestion\": {\"paragraph\": True}\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"location\": {\"index\": current_index}\n",
        "        }\n",
        "    })\n",
        "    current_index += 1\n",
        "\n",
        "# Add final page break with completion message (simplified)\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"pageBreakItem\": {}\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "# Add completion message\n",
        "all_requests.append({\n",
        "    \"createItem\": {\n",
        "        \"item\": {\n",
        "            \"title\": \"ğŸ‰ Evaluation Complete!\",\n",
        "            \"description\": \"Thank you for completing the evaluation. Your responses have been automatically saved to our spreadsheet. You may now submit the form.\",\n",
        "            \"textItem\": {}\n",
        "        },\n",
        "        \"location\": {\"index\": current_index}\n",
        "    }\n",
        "})\n",
        "current_index += 1\n",
        "\n",
        "print(f\"ğŸ“ Prepared {len(all_requests)} form items with enhanced page breaks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54vAIO0naaXC",
        "outputId": "94580867-6678-47e9-cff7-094792210442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Adding form items...\n",
            "âœ… Batch 1/9 - Added 3 items (Progress: 11.1%)\n",
            "âœ… Batch 2/9 - Added 3 items (Progress: 22.2%)\n",
            "âœ… Batch 3/9 - Added 3 items (Progress: 33.3%)\n",
            "âœ… Batch 4/9 - Added 3 items (Progress: 44.4%)\n",
            "âœ… Batch 5/9 - Added 3 items (Progress: 55.6%)\n",
            "âœ… Batch 6/9 - Added 3 items (Progress: 66.7%)\n",
            "âœ… Batch 7/9 - Added 3 items (Progress: 77.8%)\n",
            "âœ… Batch 8/9 - Added 3 items (Progress: 88.9%)\n",
            "âœ… Batch 9/9 - Added 3 items (Progress: 100.0%)\n",
            "\n",
            "ğŸ‰ Successfully added 27/27 items to the form!\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Add all form items in batches with better error handling\n",
        "print(\"ğŸš€ Adding form items...\")\n",
        "\n",
        "batch_size = 3  # Smaller batches for better reliability\n",
        "success_count = 0\n",
        "total_items = len(all_requests)\n",
        "failed_items = []\n",
        "\n",
        "for i in range(0, total_items, batch_size):\n",
        "    batch = all_requests[i:i+batch_size]\n",
        "    batch_num = (i // batch_size) + 1\n",
        "    total_batches = (total_items + batch_size - 1) // batch_size\n",
        "\n",
        "    try:\n",
        "        forms_service.forms().batchUpdate(\n",
        "            formId=form_id,\n",
        "            body={\"requests\": batch}\n",
        "        ).execute()\n",
        "        success_count += len(batch)\n",
        "        progress = (success_count / total_items) * 100\n",
        "        print(f\"âœ… Batch {batch_num}/{total_batches} - Added {len(batch)} items (Progress: {progress:.1f}%)\")\n",
        "\n",
        "        # Small delay to avoid rate limits\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Batch {batch_num} error: {str(e)[:100]}...\")\n",
        "        # Try individually with better error handling\n",
        "        for j, request in enumerate(batch):\n",
        "            item_num = i + j + 1\n",
        "            try:\n",
        "                forms_service.forms().batchUpdate(\n",
        "                    formId=form_id,\n",
        "                    body={\"requests\": [request]}\n",
        "                ).execute()\n",
        "                success_count += 1\n",
        "                print(f\"âœ… Individual item {item_num}/{total_items} added\")\n",
        "                time.sleep(0.2)\n",
        "            except Exception as eq:\n",
        "                failed_items.append({\n",
        "                    'item_number': item_num,\n",
        "                    'request': request,\n",
        "                    'error': str(eq)[:100]\n",
        "                })\n",
        "                print(f\"âŒ Individual error {item_num}: {str(eq)[:50]}...\")\n",
        "\n",
        "print(f\"\\nğŸ‰ Successfully added {success_count}/{total_items} items to the form!\")\n",
        "\n",
        "if failed_items:\n",
        "    print(f\"âš ï¸  {len(failed_items)} items failed to add:\")\n",
        "    for item in failed_items[:5]:  # Show first 5 failures\n",
        "        print(f\"   Item {item['item_number']}: {item['error']}\")\n",
        "    if len(failed_items) > 5:\n",
        "        print(f\"   ... and {len(failed_items) - 5} more\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENsSAD_ZaaXC"
      },
      "source": [
        "## ğŸ“‹ Form Information and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRIFXKptaaXC",
        "outputId": "c3d481bb-d6fd-421a-e034-eace7f7ebb09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Generating form information and links...\n",
            "âœ… Form URLs generated successfully\n",
            "ğŸ’¾ Form information saved to: /content/form_result_batch_1.json\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Get form URLs and create comprehensive results\n",
        "print(\"ğŸ“Š Generating form information and links...\")\n",
        "\n",
        "try:\n",
        "    # Get the form data to extract the correct URLs\n",
        "    form_data = forms_service.forms().get(formId=form_id).execute()\n",
        "\n",
        "    # Extract the correct URLs\n",
        "    edit_url = f\"https://docs.google.com/forms/d/{form_id}/edit\"\n",
        "\n",
        "    # The responderUri gives us the correct public URL\n",
        "    if 'responderUri' in form_data:\n",
        "        view_url = form_data['responderUri']\n",
        "    else:\n",
        "        # Fallback URL format\n",
        "        view_url = f\"https://docs.google.com/forms/d/{form_id}/viewform\"\n",
        "\n",
        "    # Responses URL - this goes to the responses tab of the edit page\n",
        "    responses_url = f\"https://docs.google.com/forms/d/{form_id}/edit#responses\"\n",
        "\n",
        "    print(\"âœ… Form URLs generated successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Using fallback URLs due to error: {e}\")\n",
        "    # Use fallback URLs\n",
        "    edit_url = f\"https://docs.google.com/forms/d/{form_id}/edit\"\n",
        "    view_url = f\"https://docs.google.com/forms/d/{form_id}/viewform\"\n",
        "    responses_url = f\"https://docs.google.com/forms/d/{form_id}/edit#responses\"\n",
        "\n",
        "# Comprehensive form information\n",
        "form_info = {\n",
        "    'form_id': form_id,\n",
        "    'edit_url': edit_url,\n",
        "    'view_url': view_url,\n",
        "    'responses_url': responses_url,\n",
        "    'spreadsheet_id': spreadsheet_id,\n",
        "    'spreadsheet_url': spreadsheet_url,\n",
        "    'total_samples': len(sample_data),\n",
        "    'json_file_used': JSON_FILE_PATH,\n",
        "    'project_id': PROJECT_ID,\n",
        "    'form_title': FORM_TITLE,\n",
        "    'batch_id': BATCH_ID,\n",
        "    'features': {\n",
        "        'progress_saving': True,\n",
        "        'page_breaks': True,\n",
        "        'spreadsheet_integration': True,\n",
        "        'enhanced_formatting': True\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to file\n",
        "output_file = f'/content/form_result_batch_{BATCH_ID}.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(form_info, f, indent=2)\n",
        "\n",
        "print(f\"ğŸ’¾ Form information saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qGDUOgfaaXC",
        "outputId": "fd34a934-572b-4a2c-d854-38116ece396c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ‰ FORM CREATION COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "\n",
            "ğŸ“ **Form Title:** BEACON LLM Model Evaluation for the Severity Assessment - Batch 1\n",
            "ğŸ†” **Form ID:** 1lN03uLEPUREUwAQ5a-QYyxn0MPe6gtXc2Vl2luPAzlE\n",
            "ğŸ“Š **Total Samples:** 2\n",
            "\n",
            "ğŸ”— **Important Links:**\n",
            "   ğŸ“ Edit Form: https://docs.google.com/forms/d/1lN03uLEPUREUwAQ5a-QYyxn0MPe6gtXc2Vl2luPAzlE/edit\n",
            "   ğŸ‘€ Public Form (Share with SMEs): https://docs.google.com/forms/d/e/1FAIpQLSfQQYVfW74cbI3ohnVZSE8MRqvHHtLrbEeyB2DlkrV-ZZM0hg/viewform\n",
            "   ğŸ“ˆ View Responses: https://docs.google.com/forms/d/1lN03uLEPUREUwAQ5a-QYyxn0MPe6gtXc2Vl2luPAzlE/edit#responses\n",
            "   ğŸ“Š Response Spreadsheet: https://docs.google.com/spreadsheets/d/1Wc9Vj_53pdDN7dnem-iVzopVPu5XP_4aY0TOubNY7qg\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Display comprehensive results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ FORM CREATION COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nğŸ“ **Form Title:** {FORM_TITLE} - Batch {BATCH_ID}\")\n",
        "print(f\"ğŸ†” **Form ID:** {form_id}\")\n",
        "print(f\"ğŸ“Š **Total Samples:** {len(sample_data)}\")\n",
        "\n",
        "print(\"\\nğŸ”— **Important Links:**\")\n",
        "print(f\"   ğŸ“ Edit Form: {edit_url}\")\n",
        "print(f\"   ğŸ‘€ Public Form (Share with SMEs): {view_url}\")\n",
        "print(f\"   ğŸ“ˆ View Responses: {responses_url}\")\n",
        "print(f\"   ğŸ“Š Response Spreadsheet: {spreadsheet_url}\")\n",
        "\n",
        "\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
